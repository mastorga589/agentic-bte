{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from scispacy.linking import EntityLinker\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated, Literal, Union\n",
    "from typing_extensions import TypedDict\n",
    "from os.path import dirname, join\n",
    "from dotenv import load_dotenv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import spacy\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your OpenAI API key\n",
    "load_dotenv(\"/Users/mastorga/Documents/BTE-LLM/.env\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"): #field to ask for OpenAI API key\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Please enter OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up SciSpacy\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "drug_disease_nlp = spacy.load(\"en_ner_bc5cdr_md\")\n",
    "nlp.add_pipe(\"scispacy_linker\", config={\"resolve_abbreviations\": True, \"linker_name\": \"umls\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idCosineSimilarity(id1: str, id2: str) -> float:\n",
    "    def getIDSynonymEntities(ids: list[str], base_url: str = \"https://name-lookup.ci.transltr.io/synonyms\"):\n",
    "        try:\n",
    "            encoded_ids = [curie.replace(\":\", \"%3A\") for curie in ids]\n",
    "            query = \"&\".join(f\"preferred_curies={eid}\" for eid in encoded_ids)\n",
    "            url = f\"{base_url}?{query}\"\n",
    "\n",
    "            response = requests.get(url, headers={\"accept\": \"application/json\"})\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            return {curie: data.get(curie, {}).get(\"names\", []) for curie in ids}\n",
    "        except Exception as e:\n",
    "            print(f\"Error querying synonyms for {ids}: {e}\")\n",
    "            return {curie: [] for curie in ids}\n",
    "    \n",
    "    def getCosineSimilarity(str1: str, str2: str):\n",
    "        str1_list = word_tokenize(str1)\n",
    "        str2_list = word_tokenize(str2)\n",
    "\n",
    "        sw = stopwords.words(\"english\")\n",
    "        str1_set = {w for w in str1_list if w not in sw}\n",
    "        str2_set = {w for w in str2_list if w not in sw}\n",
    "\n",
    "        rvector = str1_set | str2_set\n",
    "        l1, l2 = [], []\n",
    "\n",
    "        for w in rvector:\n",
    "            l1.append(1 if w in str1_set else 0)\n",
    "            l2.append(1 if w in str2_set else 0)\n",
    "\n",
    "        if sum(l1) == 0 or sum(l2) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        c = sum(l1[i] * l2[i] for i in range(len(rvector)))\n",
    "        return c / float((sum(l1) * sum(l2)) ** 0.5)\n",
    "\n",
    "    # Expand IDs via node normalization\n",
    "    id1list = list(nodeNormalize(id1))  # returns set\n",
    "    id2list = list(nodeNormalize(id2))\n",
    "\n",
    "    if not id1list or not id2list:\n",
    "        print(\"ISSUE WITH ENTITY: \")\n",
    "        print(id1)\n",
    "        return 0.0\n",
    "\n",
    "    # Fetch synonyms\n",
    "    synonyms1 = getIDSynonymEntities(id1list)\n",
    "    synonyms2 = getIDSynonymEntities(id2list)\n",
    "\n",
    "    # Flatten synonyms into one string each\n",
    "    ent1_text = \" \".join(name for names in synonyms1.values() for name in names)\n",
    "    ent2_text = \" \".join(name for names in synonyms2.values() for name in names)\n",
    "\n",
    "    return getCosineSimilarity(ent1_text, ent2_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodeNormalize(entity: str):\n",
    "    try:\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "    \n",
    "        payload = {\n",
    "            \"curies\": [entity],\n",
    "            \"conflate\": True,\n",
    "            \"description\": True,\n",
    "            \"drug_chemical_conflate\": False\n",
    "        }\n",
    "    \n",
    "        response = requests.post(\n",
    "            \"https://nodenormalization-sri.renci.org/1.5/get_normalized_nodes\",\n",
    "            headers=headers,\n",
    "            json=payload\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "    \n",
    "        data = response.json()\n",
    "        entry = data.get(entity)  # access the entityâ€™s entry\n",
    "        ids = set()\n",
    "    \n",
    "        if not entry:\n",
    "            return []\n",
    "    \n",
    "        # Main id\n",
    "        if \"id\" in entry and \"identifier\" in entry[\"id\"]:\n",
    "            ids.add(entry[\"id\"][\"identifier\"])\n",
    "    \n",
    "        # Equivalent IDs\n",
    "        for equiv in entry.get(\"equivalent_identifiers\", []):\n",
    "            identifier = equiv.get(\"identifier\")\n",
    "            if identifier:\n",
    "                ids.add(identifier.strip(\"[]'\\\" \"))\n",
    "\n",
    "        if len(ids) < 1:\n",
    "            print(entity)\n",
    "        \n",
    "        return ids\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing {entity}: {e}\")\n",
    "        return set()\n",
    "\n",
    "def checkAnswer(result, groundTruth): \n",
    "    if nodeNormalizationTest(result, groundTruth): \n",
    "        return True \n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodeNormalizationTest(ent: str, gtruth: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if ent and gtruth share any normalized IDs.\n",
    "    \"\"\"\n",
    "    ent_ids = nodeNormalize(ent)       \n",
    "    gtruth_ids = nodeNormalize(gtruth)\n",
    "\n",
    "    return len(set(ent_ids) & set(gtruth_ids)) > 0  # intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERNToolWrapper:\n",
    "    def __init__(self, url: str = \"http://bern2.korea.ac.kr/plain\"):\n",
    "        self.url = url\n",
    "\n",
    "    def invoke(self, input: dict) -> dict:\n",
    "        text = input.get(\"query\", \"\")\n",
    "        try:\n",
    "            response = requests.post(self.url, json={\"text\": text})\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            annotations = data.get(\"annotations\", [])\n",
    "        except Exception as e:\n",
    "            print(f\"BERN request failed for '{text}': {e}\")\n",
    "            return {}\n",
    "\n",
    "        results = {}\n",
    "        for ann in annotations:\n",
    "            ids = ann.get(\"id\", [])\n",
    "            mention = ann.get(\"mention\", \"\")\n",
    "            prob = ann.get(\"prob\", None)\n",
    "\n",
    "            for curie in ids:\n",
    "                results[mention] = curie\n",
    "                print(mention + \" - \" + results[mention] + \"; prob: \" + str(prob))\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERNTool = BERNToolWrapper()\n",
    "\n",
    "res = BERNTool.invoke({\"query\": \"cholesterol biosynthetic process\"})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERInput(BaseModel):\n",
    "    query: str = Field(description = \"Query to extract biological entities from\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"BioNERTool\", args_schema=NERInput)\n",
    "def modifiedBioNERTool(query: str):\n",
    "    \"\"\"Extract biological entities from a query and returns them along with their ID\"\"\"\n",
    "\n",
    "\n",
    "### Step 1: Biomedical entity extraction\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "    global nlp, drug_disease_nlp\n",
    "\n",
    "    def extractEnts(query: str):\n",
    "        entities = []\n",
    "        \n",
    "        docs = [\n",
    "        nlp(query),\n",
    "        drug_disease_nlp(query)\n",
    "        ]\n",
    "\n",
    "        # Extract entity texts from each doc\n",
    "        for doc in docs:\n",
    "            for ent in doc.ents:\n",
    "                entities.append(ent.text.strip())\n",
    "\n",
    "        # Extract biological process terms using LLM\n",
    "        bp_prompt = f\"\"\"You are a helpful assistant that can extract biological processes from a given query. \n",
    "                    These might include concepts such as \"cholesterol biosynthesis\", \"Aminergic neurotransmitter loading into synaptic vesicle\", etc. Each entity should be a noun.\n",
    "\n",
    "                    You must always return the full phrase/long form of each biomedical entity \n",
    "                    \n",
    "                    Return results as a list. Return \"\" if no biological processes are in the query. DO NOT INCLUDE YOUR THOUGHTS\n",
    "                    Here is your query: {query}\"\"\"\n",
    "\n",
    "        bp_list = llm.invoke(bp_prompt).content.strip()\n",
    "        entities.append(bp_list)\n",
    "    \n",
    "        # Deduplicate while preserving order\n",
    "        entities = list(dict.fromkeys(entities))\n",
    "\n",
    "        return entities\n",
    "        \n",
    "### Step 2: Linking each entity into a semantic type\n",
    "    def classifyEnt(query: str, ent: str):\n",
    "        supportedEntTypes = [\"biologicalProcess\", \"general\"]\n",
    "        \n",
    "        class entType(TypedDict):\n",
    "            \"\"\"The most appropriate entity type given a specific entity\"\"\"\n",
    "            entType: Literal[*supportedEntTypes]\n",
    "\n",
    "        classify_prompt = f\"\"\"\n",
    "        Classify the following biomedical entity into one of: \n",
    "        {supportedEntTypes}\n",
    "\n",
    "        Biomedical entity: {ent}\n",
    "\n",
    "        For context, here is the query that the entity was extracted from: {query}\n",
    "        \"\"\"\n",
    "        chosen_type = llm.with_structured_output(entType).invoke(classify_prompt)\n",
    "\n",
    "        chosen_type = str(chosen_type[\"entType\"])\n",
    "\n",
    "        print(ent + \" - \" + chosen_type)\n",
    "        \n",
    "        return chosen_type\n",
    "\n",
    "\n",
    "### Step 3: Entity-linking using different linkers based on entity type mapping\n",
    "    def linkEnt(entList: list, query: str):\n",
    "        idList = {}\n",
    "\n",
    "        def sriNameResolver(ent: str, base_url = \"https://name-lookup.ci.transltr.io/lookup\", is_bp: bool = False, k = 50) -> list:    \n",
    "            candidates = []\n",
    "            autoComplete = True\n",
    "            \n",
    "            processed_ent = ent.replace(\" \", \"%20\")\n",
    "\n",
    "            final_url = base_url + \"?string=\" + processed_ent + \"&autocomplete=\" + str(autoComplete).lower() + \"&limit=\" + str(k)\n",
    "\n",
    "            if is_bp:\n",
    "                final_url = final_url + \"&only_prefixes=GO&biolink_type=BiologicalProcess\"\n",
    "                \n",
    "            response = requests.get(final_url, headers={\"accept\": \"application/json\"})\n",
    "        \n",
    "            candidate_list = json.loads(response.content.decode(\"utf-8\"))\n",
    "        \n",
    "            for item in candidate_list:\n",
    "                parsed = {\n",
    "                    \"label\": item.get(\"label\", \"\"),\n",
    "                    \"curie\": item.get(\"curie\", \"\"),\n",
    "                    \"score\": item.get(\"score\", \"\")\n",
    "                }\n",
    "        \n",
    "                candidates.append(parsed)\n",
    "        \n",
    "            return candidates\n",
    "\n",
    "        def remove_TUI(text):\n",
    "            parts = text.split(\"TUI\", 1)\n",
    "            return parts[0]\n",
    "        \n",
    "        def selectID(doc: object):\n",
    "            bioID = \"\"\n",
    "            candidates = {}\n",
    "\n",
    "            linker = nlp.get_pipe(\"scispacy_linker\")   \n",
    "            \n",
    "            for ent in doc.ents:\n",
    "                if ent._.kb_ents:  # Check if entity has linked knowledge base IDs\n",
    "                    for id in ent._.kb_ents:\n",
    "                        candidates[id[0]] = remove_TUI(str(linker.kb.cui_to_entity[id[0]]))\n",
    "        \n",
    "                select_prompt = f\"\"\"You are a smart biomedical assistant that can understand the context and the intent behind a query. \n",
    "                            Be careful when choosing IDs for entities that can refer to different concepts (for example, HIV can refer either to the virus or the disease; you MUST choose the most appropriate concept/definition based on the query). \n",
    "                            Use the context and the intent behind the query to choose the most appropriate ID. \n",
    "                            Here is the complete query: {query}\n",
    "                            Select the one most appropriate ID/CUI for {ent.text} from the list below:\n",
    "                            {candidates}\n",
    "                            If none of the choices are appropriate, return \"\".\n",
    "                            Otherwise, return only the ID/CUI.\n",
    "                            \"\"\"\n",
    "    \n",
    "                # LLM selects most appropriate ID from list\n",
    "                selectedID = llm.invoke(select_prompt).content.strip()\n",
    "    \n",
    "                # Extract just the UMLS CUI using regex\n",
    "                match = re.search(r\"C\\d{7}\", selectedID)\n",
    "                if match:\n",
    "                    bioID = \"UMLS:\" + match.group(0)\n",
    "                    definition = candidates[match.group(0)]\n",
    "                else:\n",
    "                    bioID = \"\"\n",
    "                    definition = \"\"\n",
    "    \n",
    "                # Printing chosen ID + definition, if any\n",
    "                print(ent.text + \" - \" + bioID + '\\n' + definition)\n",
    "\n",
    "            return bioID\n",
    "\n",
    "        def selectIDbp(entity: str, candidates: list):\n",
    "            choices = [\"\"]\n",
    "\n",
    "            for entry in candidates:\n",
    "                curie = entry.get(\"curie\")\n",
    "                choices.append(curie)\n",
    "\n",
    "            class selectedID(TypedDict):\n",
    "                \"\"\"The most appropriate CUI/ID from the given candidates\"\"\"\n",
    "                selectedID: Literal[*choices]\n",
    "            \n",
    "            select_prompt = f\"\"\"You are a smart biomedical assistant that can understand the context and the intent behind a query. \n",
    "                        Be careful when choosing IDs for entities that can refer to different concepts (for example, HIV can refer either to the virus or the disease; you MUST choose the most appropriate concept/definition based on the query). \n",
    "                        Use the context and the intent behind the query to choose the most appropriate ID. \n",
    "                        Here is the complete query: {query}\n",
    "                        Select the one most appropriate ID/CUI for {entity} from the list below:\n",
    "                        {candidates}\n",
    "                        If none of the choices are appropriate, return \"\".\n",
    "                        Otherwise, return only the ID/CUI.\n",
    "                        \"\"\"\n",
    "    \n",
    "            # LLM selects most appropriate ID from list\n",
    "            selectedID = llm.with_structured_output(selectedID).invoke(select_prompt)\n",
    "\n",
    "            bioID = str(selectedID[\"selectedID\"])\n",
    "\n",
    "            # Printing chosen ID + definition, if any\n",
    "            print(entity + \" - \" + bioID + '\\n')\n",
    "\n",
    "            return bioID\n",
    "\n",
    "        # General Pipeline            \n",
    "        for entity in entList:\n",
    "            chosenID = \"\"\n",
    "            entclass = classifyEnt(query, entity)\n",
    "            if entclass == \"biologicalProcess\":\n",
    "                chosenID = selectIDbp(entity, sriNameResolver(entity, is_bp=True))\n",
    "            else:\n",
    "                doc = nlp(entity)\n",
    "                chosenID = selectID(doc)\n",
    "                if chosenID == \"\":\n",
    "                    chosenID = selectIDbp(entity, sriNameResolver(entity, is_bp=False))\n",
    "\n",
    "            idList[entity] = chosenID\n",
    "            \n",
    "\n",
    "        return idList\n",
    "    \n",
    "    entityList = extractEnts(query)\n",
    "    bioIDs = linkEnt(entityList, query)\n",
    "\n",
    "    print(bioIDs)\n",
    "    \n",
    "    return bioIDs if bioIDs else {\"message\": \"No entities found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"BioNERTool\", args_schema=NERInput)\n",
    "def BioNERTool(query: str):\n",
    "    \"\"\"Extract biological entities from a query and returns them along with their ID\"\"\"\n",
    "\n",
    "    def remove_TUI(text):\n",
    "        parts = text.split(\"TUI\", 1)\n",
    "        return parts[0]\n",
    "\n",
    "    # Setting up nlp model\n",
    "    global nlp\n",
    "    linker = nlp.get_pipe(\"scispacy_linker\")\n",
    "\n",
    "    bioIDs = {}\n",
    "    idList = {}\n",
    "\n",
    "    llm = ChatOpenAI(temperature=0, model=\"gpt-4o\")\n",
    "    \n",
    "    doc = nlp(query)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent._.kb_ents:  # Check if entity has linked knowledge base IDs\n",
    "            for id in ent._.kb_ents:\n",
    "                idList[id[0]] = remove_TUI(str(linker.kb.cui_to_entity[id[0]]))\n",
    "\n",
    "            select_prompt = f\"\"\"You are a smart biomedical assistant that can understand the context and the intent behind a query. \n",
    "                        Be careful when choosing IDs for entities that can refer to different concepts (for example, HIV can refer either to the virus or the disease; you MUST choose the most appropriate concept/definition based on the query). \n",
    "                        Use the context and the intent behind the query to choose the most appropriate ID. \n",
    "                        Here is the complete query: {query}\n",
    "                        Select the one most appropriate ID/CUI for {ent.text} from the list below:\n",
    "                        {idList}\n",
    "                        If none of the choices are appropriate, return \"\".\n",
    "                        Otherwise, return only the ID/CUI.\n",
    "                        \"\"\"\n",
    "\n",
    "            # LLM selects most appropriate ID from list\n",
    "            selectedID = llm.invoke(select_prompt).content.strip()\n",
    "\n",
    "            # Extract just the UMLS CUI using regex\n",
    "            match = re.search(r\"C\\d{7}\", selectedID)\n",
    "            if match:\n",
    "                bioIDs[ent.text] = \"UMLS:\" + match.group(0)\n",
    "                definition = idList[match.group(0)]\n",
    "            else:\n",
    "                bioIDs[ent.text] = \"No appropriate IDs were found\"\n",
    "                definition = \"\"\n",
    "\n",
    "            # Printing chosen ID + definition, if any\n",
    "            print(ent.text + \" - \" + bioIDs[ent.text] + '\\n' + definition)\n",
    "\n",
    "            \n",
    "\n",
    "    return bioIDs if bioIDs else {\"message\": \"No entities found\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ner_test(\n",
    "    df,\n",
    "    name_col: str,\n",
    "    id_col: str,\n",
    "    tools: dict[str, object],\n",
    "    check_answer_fn,\n",
    "    similarity_fn\n",
    "):\n",
    "    \"\"\"\n",
    "    Generalizable NER test function.\n",
    "\n",
    "    Args:\n",
    "        df: pandas DataFrame with entities and ground-truth IDs\n",
    "        name_col: column containing entity names (e.g. \"bp_name\")\n",
    "        id_col: column containing ground truth IDs (e.g. \"bp\")\n",
    "        tools: dict mapping tool_name -> tool_object (must have .invoke())\n",
    "        check_answer_fn: function(result_id, groundTruth) -> \"Correct\"/\"Incorrect\"\n",
    "        similarity_fn: function(id1, id2) -> float\n",
    "\n",
    "    Returns:\n",
    "        dict with tally counts for each tool\n",
    "    \"\"\"\n",
    "    n = len(df[name_col])\n",
    "    tallies = {tool_name: 0 for tool_name in tools}\n",
    "\n",
    "    # Add results columns to df\n",
    "    for tool_name in tools:\n",
    "        df[f\"{id_col}_{tool_name}\"] = \"\"               # raw results dict\n",
    "        df[f\"{id_col}_{tool_name}_ans\"] = \"\"           # best chosen ID\n",
    "        df[f\"{id_col}_{tool_name}_correct\"] = False    # correctness flag\n",
    "        df[f\"{id_col}_{tool_name}_similarity\"] = -1.0  # cosine similarity\n",
    "\n",
    "    for index, entity in enumerate(df[name_col]):\n",
    "        groundTruth = df.iloc[index][id_col]\n",
    "        print(f\"\\n{index+1}. Entity: {entity}\\nGround truth: {groundTruth}\\n\")\n",
    "\n",
    "        # Store per-entity results\n",
    "        entity_results = {}\n",
    "\n",
    "        for tool_name, tool in tools.items():\n",
    "            best_ans = None\n",
    "            best_sim = -1.0\n",
    "            check = False\n",
    "\n",
    "            try:\n",
    "                # Run tool\n",
    "                results = tool.invoke(input={\"query\": entity})\n",
    "                df.at[index, f\"{id_col}_{tool_name}\"] = results\n",
    "\n",
    "                # Pick best candidate\n",
    "                for candidate_id in results.values():\n",
    "                    sim = similarity_fn(candidate_id, groundTruth)\n",
    "                    if sim > best_sim:\n",
    "                        best_ans, best_sim = candidate_id, sim\n",
    "                        check = check_answer_fn(best_ans, groundTruth)\n",
    "                    if sim == 1:\n",
    "                        check = True\n",
    "                        break\n",
    "\n",
    "                # Update DataFrame\n",
    "                df.at[index, f\"{id_col}_{tool_name}_ans\"] = best_ans\n",
    "                df.at[index, f\"{id_col}_{tool_name}_correct\"] = check\n",
    "                df.at[index, f\"{id_col}_{tool_name}_similarity\"] = best_sim\n",
    "                if check == True:\n",
    "                    tallies[tool_name] += 1\n",
    "                    df.at[index, f\"{id_col}_{tool_name}_correct\"] = True\n",
    "\n",
    "                print(f\"\\n{tool_name} answer: {best_ans}; cosine similarity = {best_sim:.3f}\\n\\n-----\")\n",
    "\n",
    "            except Exception as e:\n",
    "                best_ans = None\n",
    "                best_sim = -1.0\n",
    "                check = f\"Error: {e}\"\n",
    "\n",
    "            # Save to entity summary\n",
    "            entity_results[tool_name] = {\n",
    "                \"ans\": best_ans,\n",
    "                \"sim\": best_sim,\n",
    "                \"check\": check,\n",
    "                \"tally\": tallies[tool_name]\n",
    "            }\n",
    "\n",
    "        # === Print summary for this entity ===\n",
    "        for tool_name, result in entity_results.items():\n",
    "            print(f\"\"\"{tool_name} answer: {result['ans']} - {result['check']}\n",
    "    cosine similarity with gt: {result['sim']:.3f}\n",
    "    tally: {result['tally']} / {n}\\n\"\"\")\n",
    "\n",
    "        print(\"{\\n---------------------------\\n\")\n",
    "\n",
    "    return tallies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "DMDB = pd.read_csv('/Users/mastorga/Documents/BTE-LLM/Prototype/data/DMDB_go_bp_filtered_jjoy_05_08_2025.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugDiseaseSet = DMDB.sample(100)\n",
    "drugDiseaseSet[\"pairID\"] = drugDiseaseSet.index\n",
    "drugDiseaseSet = drugDiseaseSet.reset_index(drop=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugDiseaseSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaboliteDB = pd.read_csv('/Users/mastorga/Documents/BTE-LLM/Prototype/data/DMDB_chebi_metabolite_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaboliteSet = metaboliteDB.sample(100)\n",
    "metaboliteSet[\"pairID\"] = metaboliteSet.index\n",
    "metaboliteSet = metaboliteSet.reset_index(drop=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "metaboliteSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneDB = pd.read_csv('/Users/mastorga/Documents/BTE-LLM/Prototype/data/DMDB_mechanistic_genes_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneSet = geneDB.sample(100)\n",
    "geneSet[\"pairID\"] = geneSet.index\n",
    "geneSet[\"gene_str\"] = geneSet[\"protein_gene_symbol\"].apply(lambda x: x.strip(\"\"\"['\"]\"\"\"))\n",
    "geneSet[\"protein_str\"] = geneSet[\"protein_name\"].apply(lambda x: x.strip(\"\"\"['\"]\"\"\"))\n",
    "geneSet[\"protein_ID\"] = geneSet[\"protein\"].apply(lambda x: x.strip(\"\"\"['\"]\"\"\").replace(\"UniProt:\", \"UniProtKB:\"))\n",
    "geneSet = geneSet.reset_index(drop=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "geneSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERNTool = BERNToolWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = {\n",
    "    \"BioNER\": BioNERTool,\n",
    "    \"modifiedBioNER\": modifiedBioNERTool,\n",
    "    \"BERN2\": BERNTool\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BIOLOGICAL PROCESS NER\n",
    "bp_tallies = run_ner_test(\n",
    "    df=drugDiseaseSet,\n",
    "    name_col=\"bp_name\",\n",
    "    id_col=\"bp\",\n",
    "    tools=tools,\n",
    "    check_answer_fn=checkAnswer,\n",
    "    similarity_fn=idCosineSimilarity\n",
    ")\n",
    "\n",
    "print(\"Final tallies for the BIOLOGICAL PROCESS entity type:\", bp_tallies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DISEASE NER\n",
    "disease_tallies = run_ner_test(\n",
    "    df=drugDiseaseSet,\n",
    "    name_col=\"disease_name\",\n",
    "    id_col=\"disease\",\n",
    "    tools=tools,\n",
    "    check_answer_fn=checkAnswer,\n",
    "    similarity_fn=idCosineSimilarity\n",
    ")\n",
    "\n",
    "print(\"Final tallies for the DISEASE entity type:\", disease_tallies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DRUG NER\n",
    "drug_tallies = run_ner_test(\n",
    "    df=drugDiseaseSet,\n",
    "    name_col=\"drug_name\",\n",
    "    id_col=\"Drug_MeshID\",\n",
    "    tools=tools,\n",
    "    check_answer_fn=checkAnswer,\n",
    "    similarity_fn=idCosineSimilarity\n",
    ")\n",
    "\n",
    "print(\"Final tallies for the DRUG entity type:\", drug_tallies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save responses\n",
    "\n",
    "drugDiseaseSet.to_excel('/Users/mastorga/Documents/BTE-LLM/Prototype/logs/NER/09.03.25_100pairs_drug_disease_bp.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# METABOLITE NER\n",
    "metabolite_tallies = run_ner_test(\n",
    "    df=metaboliteSet,\n",
    "    name_col=\"metabolite_name_str\",\n",
    "    id_col=\"metabolite\",\n",
    "    tools=tools,\n",
    "    check_answer_fn=checkAnswer,\n",
    "    similarity_fn=idCosineSimilarity\n",
    ")\n",
    "\n",
    "print(\"Final tallies for the METABOLITE entity type:\", metabolite_tallies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save responses\n",
    "\n",
    "metaboliteSet.to_excel('/Users/mastorga/Documents/BTE-LLM/Prototype/logs/NER/09.03.25_100pairs_metabolite.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENE NER\n",
    "gene_tallies = run_ner_test(\n",
    "    df=geneSet,\n",
    "    name_col=\"gene_str\",\n",
    "    id_col=\"protein_ID\",\n",
    "    tools=tools,\n",
    "    check_answer_fn=checkAnswer,\n",
    "    similarity_fn=idCosineSimilarity\n",
    ")\n",
    "\n",
    "print(\"Final tallies for the GENE entity type:\", gene_tallies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROTEIN NER\n",
    "protein_tallies = run_ner_test(\n",
    "    df=geneSet,\n",
    "    name_col=\"protein_str\",\n",
    "    id_col=\"protein_ID\",\n",
    "    tools=tools,\n",
    "    check_answer_fn=checkAnswer,\n",
    "    similarity_fn=idCosineSimilarity\n",
    ")\n",
    "\n",
    "print(\"Final tallies for the PROTEIN entity type:\", protein_tallies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save responses\n",
    "\n",
    "geneSet.to_excel('/Users/mastorga/Documents/BTE-LLM/Prototype/logs/NER/09.03.25_100pairs_mechanisticgenes.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# Enhanced GoT System - Debugging & Scientific Validation Guide

## ðŸ”¬ Overview

This guide demonstrates how to use the comprehensive debugging system for the Enhanced GoT framework. The debugging system provides detailed scientific validation to ensure the system produces scientifically sound results like your Brucellosis example.

## ðŸš€ Quick Start

### Method 1: Interactive Menu System
```bash
python run_debug_demo.py
```

This launches an interactive menu where you can choose:
1. **Full System Debugging** - Complete analysis with all validation steps
2. **Individual Component Testing** - Test each MCP tool separately  
3. **Quick System Test** - Basic system validation
4. **Entity Extraction Test** - Test only bio_ner tool
5. **TRAPI Query Building Test** - Test only build_trapi_query tool
6. **BTE API Test** - Test only call_bte_api tool

### Method 2: Direct Execution
```bash
python debug_enhanced_got_demo.py
```

Runs the full comprehensive debugging demonstration directly.

## ðŸ” What the Debugging System Validates

### 1. **Entity Extraction Validation**
- âœ… **Biomedical Entity Recognition**: Verifies entities are properly classified as diseases, drugs, genes, etc.
- âœ… **Entity ID Assignment**: Confirms entities have valid biomedical IDs (MONDO:, CHEBI:, NCBIGene:, etc.)
- âœ… **Entity Type Accuracy**: Validates entity types match biomedical ontologies

**Example Output:**
```
ðŸ§¬ STEP 1: ENTITY EXTRACTION & VALIDATION
-----------------------------------------
Raw Entity Response: 1247 characters
Entities Found: 3

ðŸ“Š ENTITY VALIDATION RESULTS:
  â€¢ Total entities: 3
  â€¢ Valid biomedical entities: 3
  â€¢ Entity types found: ['disease', 'biologicalprocess', 'drug']

ðŸ·ï¸  DETAILED ENTITY BREAKDOWN:
  1. Brucellosis
     Type: disease
     ID: MONDO:0005683
     Valid biomedical: âœ…
     Has valid ID: âœ…

  2. translation
     Type: biologicalprocess
     ID: GO:0006412
     Valid biomedical: âœ…
     Has valid ID: âœ…
```

### 2. **TRAPI Query Structure Validation**
- âœ… **Valid TRAPI Format**: Confirms query follows TRAPI specification
- âœ… **Biomedical Categories**: Verifies nodes use proper biolink categories
- âœ… **Scientific Predicates**: Validates edges use meaningful biomedical relationships
- âœ… **Entity ID Integration**: Ensures extracted entities are properly used in queries

**Example Output:**
```
ðŸ“‹ TRAPI QUERY ANALYSIS:
      Valid TRAPI: âœ…
      Nodes: 2
      Edges: 1
      ðŸ“Š TRAPI Structure:
        Node n0:
          Categories: ['biolink:Disease']
          IDs: ['MONDO:0005683']
        Node n1:
          Categories: ['biolink:SmallMolecule']
          IDs: []
        Edge e0:
          Predicates: ['biolink:treats']
          From: n1 To: n0
```

### 3. **Knowledge Graph Results Validation**
- âœ… **Relationship Quality**: Analyzes confidence scores and relationship validity
- âœ… **Entity Name Resolution**: Verifies raw IDs are resolved to readable names
- âœ… **Predicate Distribution**: Shows types of biomedical relationships found
- âœ… **Scientific Soundness**: Validates relationships make biological sense

**Example Output:**
```
ðŸ”— API RESULTS ANALYSIS:
      Total results: 12
      Valid relationships: 12
      Confidence distribution:
        High (>0.7): 4
        Medium (0.4-0.7): 6
        Low (<0.4): 2
      Entity name resolution: 92.3% (24/26)
      ðŸ“‹ Sample relationships:
        1. doxycycline â†’ treats â†’ Brucellosis
           Confidence: 0.856
        2. streptomycin â†’ treats â†’ Brucellosis
           Confidence: 0.734
```

### 4. **Domain Expertise Integration Validation**
- âœ… **Pharmaceutical Context**: Checks for disease/pathophysiology explanation
- âœ… **Mechanistic Reasoning**: Verifies mechanism of action explanations
- âœ… **Drug Classification**: Confirms proper antibiotic class categorization
- âœ… **Expert Inference**: Validates use of domain knowledge to fill gaps
- âœ… **Specific Examples**: Ensures concrete drug examples with mechanisms

**Example Output:**
```
ðŸ§  STEP 4: DOMAIN EXPERTISE ANALYSIS
------------------------------------
Final answer length: 1456 characters

ðŸ”¬ Domain expertise integration analysis:
  âœ… Pharmaceutical Context: ['brucellosis', 'infectious disease', 'bacteria']
  âœ… Mechanistic Explanation: ['translation', 'protein synthesis', 'ribosome']
  âœ… Drug Classification: ['antibiotic', 'tetracycline', 'aminoglycoside']
  âœ… Expert Inference: ['medicinal chemistry', 'drug class']
  âœ… Specific Examples: ['doxycycline', 'streptomycin']
  âœ… Mechanism Details: ['30S ribosome', 'peptidyl transferase']

ðŸ“Š Domain Expertise Score: 100.0% (6/6)
ðŸ† EXCELLENT: High-level pharmaceutical sciences expertise demonstrated!
```

## ðŸ”§ Individual Component Testing

### Entity Extraction Test
Tests the bio_ner MCP tool to ensure proper biomedical entity recognition:

```bash
python run_debug_demo.py
# Select option 4
```

**What it validates:**
- Entity extraction accuracy
- Biomedical type classification
- Entity ID assignment
- Confidence scoring

### TRAPI Query Building Test  
Tests the build_trapi_query MCP tool for proper query construction:

```bash
python run_debug_demo.py
# Select option 5
```

**What it validates:**
- TRAPI specification compliance
- Proper biolink category usage
- Entity ID integration
- Edge/predicate selection

### BTE API Test
Tests the call_bte_api MCP tool for knowledge graph querying:

```bash
python run_debug_demo.py  
# Select option 6
```

**What it validates:**
- API connectivity and response
- Result structure and quality
- Entity name resolution
- Confidence scoring

## ðŸ“Š Scientific Validation Criteria

The debugging system uses these criteria to assess scientific soundness:

### âœ… **PASS Criteria**
- **Entity Extraction Success**: â‰¥1 valid biomedical entity extracted
- **TRAPI Queries Valid**: â‰¥80% of TRAPI queries follow specification
- **Name Resolution Success**: â‰¥70% of entity IDs resolved to readable names
- **Domain Expertise Integration**: â‰¥60% of expertise indicators present
- **Scientific Relationships Found**: â‰¥1 valid biomedical relationship discovered

### ðŸ“ˆ **Quality Scoring**
- **80-100%**: Production-ready with high scientific rigor
- **60-79%**: Good scientific foundation, minor improvements needed
- **<60%**: Requires significant improvements for scientific accuracy

## ðŸŽ¯ Expected Results for Brucellosis Query

For the query "What drugs can treat Brucellosis by targeting translation?", a scientifically sound system should demonstrate:

### Domain Context
- Explanation of Brucellosis as bacterial infection
- Importance of translation for bacterial survival

### Mechanistic Understanding
- Translation process and ribosome function
- How translation inhibitors kill bacteria

### Expert Classification
- Tetracyclines (doxycycline): 30S ribosome inhibitor
- Aminoglycosides (streptomycin): translation fidelity inhibitor  
- Chloramphenicol: peptidyl transferase inhibitor
- Rifamycins (rifampicin): indirect via transcription inhibition

### Scientific Evidence
- TRAPI queries targeting disease-drug relationships
- Knowledge graph evidence for therapeutic uses
- Resolved entity names (not raw UMLS/MONDO IDs)

## ðŸ› Troubleshooting

### Common Issues

**1. Entity Extraction Fails**
```
âŒ Entity extraction failed: OpenAI API key not found
```
**Solution**: Set your OpenAI API key in environment variables:
```bash
export AGENTIC_BTE_OPENAI_API_KEY="your-key-here"
```

**2. MCP Tool Not Found**
```
âŒ TRAPI building failed: Unknown tool: build_trapi_query
```
**Solution**: Ensure MCP server is running and tools are available

**3. BTE API Connection Issues**
```
âŒ BTE API call failed: Connection timeout
```
**Solution**: Check internet connection and BTE API availability

**4. Low Entity Name Resolution**
```
Entity name resolution: 23.1% (3/13)
```
**Solution**: This indicates the system isn't properly resolving entity IDs to readable names. Check entity resolution components.

### Debug Logging

Enable detailed logging for troubleshooting:
```bash
export AGENTIC_BTE_LOG_LEVEL=DEBUG
python debug_enhanced_got_demo.py
```

## ðŸ”¬ System Validation Report

The debugging system generates a comprehensive validation report:

```
ðŸ“ˆ STEP 6: SCIENTIFIC VALIDATION SUMMARY
-----------------------------------------
âœ… VALIDATION RESULTS:
  Entity Extraction Success: âœ… PASS
  Trapi Queries Valid: âœ… PASS
  Name Resolution Success: âœ… PASS
  Domain Expertise Integration: âœ… PASS
  Scientific Relationships Found: âœ… PASS

ðŸŽ¯ OVERALL SCIENTIFIC VALIDATION: 100.0% (5/5)
ðŸ† SYSTEM STATUS: Production-ready with high scientific rigor!
```

This validation ensures the system produces responses with the same level of sophistication as your Brucellosis example, combining knowledge graph evidence with domain expertise to provide scientifically accurate and comprehensive answers.

## ðŸ“ Usage Examples

### Quick Validation
```bash
python run_debug_demo.py
# Select option 3 for quick test
```

### Full Scientific Analysis  
```bash
python run_debug_demo.py
# Select option 1 for comprehensive debugging
```

### Component-by-Component Testing
```bash
python run_debug_demo.py
# Select option 2 for individual component tests
```

The debugging system ensures the Enhanced GoT framework maintains the scientific rigor and domain expertise demonstrated in your Brucellosis example while providing full transparency into the system's reasoning process.